{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fa12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "import conntility\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5cc9b",
   "metadata": {},
   "source": [
    "## Part 1:\n",
    "Measure the strengths of statistical interactions in connectivity based on individual morphologies that are not capture by a fourth-order simplifed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f80eb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mtype\n",
       "L23_PTPC    14994\n",
       "L23_STPC     5028\n",
       "IN              0\n",
       "L4_PC           0\n",
       "L56_PC          0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_rat = \"/gpfs/bbp.cscs.ch/project/proj159/home/barros/conn_matrix/Rat_623um_squared_struc_conmat_filtered_compressed.h5\"\n",
    "fn_human = \"/gpfs/bbp.cscs.ch/project/proj159/home/barros/conn_matrix/Human_960um_squared_struc_conmat_filtered_compressed.h5\"\n",
    "\n",
    "loaded = \"human\"  # Set to human to analyze that instead\n",
    "extent_xz = 900\n",
    "nbins_xz = 31\n",
    "extent_y = 700\n",
    "nbins_y = 41\n",
    "\n",
    "if loaded == \"rat\":\n",
    "    M_h = conntility.ConnectivityMatrix.from_h5(fn_rat)\n",
    "    col_y = \"depth\"\n",
    "    col_xz = [\"ss_flat_x\", \"ss_flat_y\"]\n",
    "elif loaded == \"human\":\n",
    "    M_h = conntility.ConnectivityMatrix.from_h5(fn_human)\n",
    "    col_y = \"y\"\n",
    "    col_xz = [\"x\", \"z\"]\n",
    "\n",
    "dbins_xz = numpy.hstack([[0, 1E-12], numpy.linspace(1E-12, extent_xz, nbins_xz)])\n",
    "binid_xz = numpy.arange(0, nbins_xz + 1)\n",
    "\n",
    "dbins_y = numpy.linspace(-extent_y, extent_y, nbins_y)\n",
    "binid_y = numpy.arange(0, nbins_y + 1)\n",
    "\n",
    "M_h.vertices[\"mtype\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "_coords = col_xz + [col_y]\n",
    "tree = KDTree(M_h.vertices[_coords].values)\n",
    "\n",
    "_, nn_id = tree.query(M_h.vertices[_coords], k=2)\n",
    "nn_id = nn_id[:, 1]  # nn_id[:, 0] is the original node, which has distance 0. nn_id[:, 1] is neighbor\n",
    "\n",
    "# Lookup from pre / post ids to edge ids\n",
    "edge_id_lookup = M_h._edge_indices.reset_index(drop=True).reset_index().set_index([\"row\", \"col\"])[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28739ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_pre_chunk(chunk_pre):\n",
    "    # Which offset bin the pairs fall into\n",
    "    Dxz = cdist(M_h.vertices.iloc[chunk_pre][col_xz], M_h.vertices[col_xz]) # PRE X POST\n",
    "    Dxz = numpy.digitize(Dxz, dbins_xz) - 2  # -2 means distance = 0 will be bin id -1\n",
    "\n",
    "    Dy = M_h.vertices.iloc[chunk_pre][[col_y]].values - M_h.vertices[[col_y]].values.transpose() # PRE X POST\n",
    "    Dy = numpy.digitize(Dy, dbins_y) - 1  # NOTE: Negative values -> upwards connection\n",
    "    \n",
    "    # Numer of touches between them\n",
    "    j, i = numpy.meshgrid(numpy.arange(len(M_h)), chunk_pre)\n",
    "    assert j.shape == Dy.shape\n",
    "    con_index = pandas.MultiIndex.from_frame(pandas.DataFrame({\"row\": i.flatten(), \"col\": j.flatten()}))\n",
    "    edge_ids = edge_id_lookup.reindex(con_index, fill_value=-1).values\n",
    "    \n",
    "    touch_count = numpy.zeros(len(edge_ids))\n",
    "    v = edge_ids > 0\n",
    "    touch_count[v] = M_h.edges[\"count\"].values[edge_ids[v]]\n",
    "    \n",
    "    # Number of touches with nearest neighbor (pre)\n",
    "    _pre = nn_id[i.flatten()]; _post = j.flatten()\n",
    "    con_index = pandas.MultiIndex.from_frame(pandas.DataFrame({\"row\": _pre, \"col\": _post}))\n",
    "    edge_ids = edge_id_lookup.reindex(con_index, fill_value=-1).values\n",
    "    \n",
    "    touch_count_nnpre = numpy.zeros(len(edge_ids))\n",
    "    v = edge_ids > 0\n",
    "    touch_count_nnpre[v] = M_h.edges[\"count\"].values[edge_ids[v]]\n",
    "    collision_pre = _pre != _post\n",
    "    \n",
    "    # Number of touches with nearest neighbor (post)\n",
    "    _pre = i.flatten(); _post = nn_id[j.flatten()]\n",
    "    con_index = pandas.MultiIndex.from_frame(pandas.DataFrame({\"row\": _pre, \"col\": _post}))\n",
    "    edge_ids = edge_id_lookup.reindex(con_index, fill_value=-1).values\n",
    "    \n",
    "    touch_count_nnpost = numpy.zeros(len(edge_ids))\n",
    "    v = edge_ids > 0\n",
    "    touch_count_nnpost[v] = M_h.edges[\"count\"].values[edge_ids[v]]\n",
    "    collision_post = _pre != _post\n",
    "    \n",
    "    # Count instances of each\n",
    "    ret_pre = pandas.DataFrame({\n",
    "        \"xz\": Dxz.flatten()[collision_pre],\n",
    "        \"y\": Dy.flatten()[collision_pre],\n",
    "        \"touches_pair\": touch_count[collision_pre],\n",
    "        \"touches_nn_pre\": touch_count_nnpre[collision_pre],\n",
    "    }).value_counts()\n",
    "    \n",
    "    ret_post = pandas.DataFrame({\n",
    "        \"xz\": Dxz.flatten()[collision_post],\n",
    "        \"y\": Dy.flatten()[collision_post],\n",
    "        \"touches_pair\": touch_count[collision_post],\n",
    "        \"touches_nn_post\": touch_count_nnpost[collision_post],\n",
    "    }).value_counts()\n",
    "    return ret_pre, ret_post\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In each offset-bin: How many pairs exist?\n",
    "full_master_pre = []\n",
    "full_master_post = []\n",
    "chunk_sz = 1000\n",
    "chunking = numpy.arange(0, len(M_h) + chunk_sz, chunk_sz)\n",
    "\n",
    "chunk_pre = numpy.arange(chunking[0], numpy.minimum(chunking[1], len(M_h)))\n",
    "full_master_pre, full_master_post = for_pre_chunk(chunk_pre)\n",
    "\n",
    "for a, b in tqdm.tqdm(list(zip(chunking[1:-1], chunking[2:]))):\n",
    "    chunk_pre = numpy.arange(a, numpy.minimum(b, len(M_h)))\n",
    "    new_master_pre, new_master_post = for_pre_chunk(chunk_pre)\n",
    "    full_master_pre = full_master_pre.add(new_master_pre, fill_value=0)\n",
    "    full_master_post = full_master_post.add(new_master_post, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_master_pre = full_master_pre.reset_index()\n",
    "full_master_post = full_master_post.reset_index()\n",
    "\n",
    "bin_centers_y = numpy.hstack([\n",
    "    0.5 * (dbins_y[:-1] + dbins_y[1:]),\n",
    "    dbins_y[-1] + 0.5 * numpy.mean(numpy.diff(dbins_y))\n",
    "])\n",
    "bin_centers_xz = numpy.hstack([\n",
    "    0.5 * (dbins_xz[1:-1] + dbins_xz[2:]),\n",
    "    dbins_xz[-1] + 0.5 * numpy.mean(numpy.diff(dbins_xz[1:]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_v = full_master_pre[\"xz\"] >= 0\n",
    "full_master_pre[\"xz\"][_v] = bin_centers_xz[full_master_pre[\"xz\"][_v]]\n",
    "full_master_pre[\"y\"] = bin_centers_y[full_master_pre[\"y\"]]\n",
    "\n",
    "_v = full_master_post[\"xz\"] >= 0\n",
    "full_master_post[\"xz\"][_v] = bin_centers_xz[full_master_post[\"xz\"][_v]]\n",
    "full_master_post[\"y\"] = bin_centers_y[full_master_post[\"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fn = \"/gpfs/bbp.cscs.ch/project/proj159/home/reimann/connectivity_higher_order_effect.h5\"\n",
    "\n",
    "full_master_pre.to_hdf(out_fn, key=\"{0}/pre\".format(loaded))\n",
    "full_master_post.to_hdf(out_fn, key=\"{0}/post\".format(loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6e852",
   "metadata": {},
   "source": [
    "## Part 2:\n",
    "The above characterizes statistical interactions within one spatial bin. Here, we consider interactions _between_ bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c49e4dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: I repeat some of the parameterization from Part 1. In case you want to run only this part.\n",
    "extent_xz = 900\n",
    "nbins_xz = 31\n",
    "extent_y = 700\n",
    "nbins_y = 41\n",
    "\n",
    "dbins_xz = numpy.hstack([[0, 1E-12], numpy.linspace(1E-12, extent_xz, nbins_xz)])\n",
    "binid_xz = numpy.arange(0, nbins_xz + 1)\n",
    "\n",
    "dbins_y = numpy.linspace(-extent_y, extent_y, nbins_y)\n",
    "binid_y = numpy.arange(0, nbins_y + 1)\n",
    "\n",
    "edge_id_lookup = M_h._edge_indices.reset_index(drop=True).reset_index().set_index([\"row\", \"col\"])[\"index\"]\n",
    "\n",
    "def for_chunk(chunk, interaction_for=\"pre\"):\n",
    "    # Which offset bin the pairs fall into\n",
    "    if interaction_for == \"pre\":\n",
    "        Dxz = cdist(M_h.vertices.iloc[chunk][col_xz], M_h.vertices[col_xz]) # PRE X POST\n",
    "        Dxz = numpy.digitize(Dxz, dbins_xz) - 2  # -2 means distance = 0 will be bin id -1\n",
    "\n",
    "        Dy = M_h.vertices.iloc[chunk][[col_y]].values - M_h.vertices[[col_y]].values.transpose() # PRE X POST\n",
    "        Dy = numpy.digitize(Dy, dbins_y) - 1  # NOTE: Negative values -> upwards connection\n",
    "        \n",
    "        j, i = numpy.meshgrid(numpy.arange(len(M_h)), chunk)\n",
    "        node_id = i.flatten()\n",
    "    elif interaction_for == \"post\":\n",
    "        Dxz = cdist(M_h.vertices[col_xz], M_h.vertices.iloc[chunk][col_xz]) # PRE X POST\n",
    "        Dxz = numpy.digitize(Dxz, dbins_xz) - 2  # -2 means distance = 0 will be bin id -1\n",
    "\n",
    "        Dy = M_h.vertices[[col_y]].values - M_h.vertices.iloc[chunk][[col_y]].values.transpose() # PRE X POST\n",
    "        Dy = numpy.digitize(Dy, dbins_y) - 1  # NOTE: Negative values -> upwards connection\n",
    "        \n",
    "        j, i = numpy.meshgrid(chunk, numpy.arange(len(M_h)))\n",
    "        node_id = j.flatten()\n",
    "    \n",
    "    # Numer of touches between them\n",
    "    assert j.shape == Dy.shape\n",
    "    con_index = pandas.MultiIndex.from_frame(pandas.DataFrame({\"row\": i.flatten(), \"col\": j.flatten()}))\n",
    "    edge_ids = edge_id_lookup.reindex(con_index, fill_value=-1).values\n",
    "    \n",
    "    touch_count = numpy.zeros(len(edge_ids))\n",
    "    v = edge_ids > 0\n",
    "    touch_count[v] = M_h.edges[\"count\"].values[edge_ids[v]]\n",
    "    touch_count.reshape(Dy.shape)\n",
    "        \n",
    "    # Count instances of each\n",
    "    ret = pandas.DataFrame({\n",
    "        \"xz\": Dxz.flatten(),\n",
    "        \"y\": Dy.flatten(),\n",
    "        \"touches_pair\": touch_count,\n",
    "        \"node_id\": node_id,\n",
    "    }).value_counts()\n",
    "    \n",
    "    return ret\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43e1fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [05:54<00:00, 32.22s/it]\n"
     ]
    }
   ],
   "source": [
    "df_for_pre = []\n",
    "df_for_post = []\n",
    "\n",
    "chunk_sz = 2000\n",
    "chunking = numpy.arange(0, len(M_h) + chunk_sz, chunk_sz)\n",
    "\n",
    "for a, b in tqdm.tqdm(list(zip(chunking[:-1], chunking[1:]))):\n",
    "    chunk = numpy.arange(a, numpy.minimum(b, len(M_h)))\n",
    "    df_for_pre.append(for_chunk(chunk, interaction_for=\"pre\"))\n",
    "    df_for_post.append(for_chunk(chunk, interaction_for=\"post\"))\n",
    "    \n",
    "df_for_pre = pandas.concat(df_for_pre, axis=0)\n",
    "df_for_post = pandas.concat(df_for_post, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b053f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We introduce a threshold for minimum number of touches to make the results sparser. That enables simplex counting later\n",
    "thresh = 5  # HOW MANY TOUCHES NEED TO BE REACHED FOR A CONNECTION\n",
    "\n",
    "# For each pre- or post-neuron: How many partners does it have in each offset bin (N) and what fraction is connected (P)?\n",
    "def count_n_and_p(df_in):\n",
    "    M = df_in.pivot(index=\"touches_pair\", columns=\"node_id\", values=\"count\") # \"node_id\"\n",
    "    V = pandas.concat([M.sum(axis=0), M.loc[thresh:].sum(axis=0) / M.sum(axis=0)], axis=1, keys=[\"N\", \"P\"])\n",
    "    return V\n",
    "\n",
    "df_n_p_pre = df_for_pre.reset_index().groupby([\"xz\", \"y\"]).apply(count_n_and_p)\n",
    "df_n_p_post = df_for_post.reset_index().groupby([\"xz\", \"y\"]).apply(count_n_and_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f902eb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xz</th>\n",
       "      <th>y</th>\n",
       "      <th>node_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 N    P\n",
       "xz y  node_id          \n",
       "-1 20 0        1.0  0.0\n",
       "      1        1.0  0.0\n",
       "      2        1.0  0.0\n",
       "      3        1.0  0.0\n",
       "      4        1.0  0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_p_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b8096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall mean connection probability in each offset bin\n",
    "mn_P_pre = df_n_p_pre.drop(-1).groupby([\"xz\", \"y\"]).apply(lambda _x: (_x[\"N\"] * _x[\"P\"]).sum() / _x[\"N\"].sum())\n",
    "mn_P_post = df_n_p_post.drop(-1).groupby([\"xz\", \"y\"]).apply(lambda _x: (_x[\"N\"] * _x[\"P\"]).sum() / _x[\"N\"].sum())\n",
    "\n",
    "# What is the correlation between observed values of \"P\" over pre- or post-neurons in a given offset bin?\n",
    "def observations_to_cc_of_offset_bins(df_in, mode=\"valid\"):\n",
    "    df_cc = df_in.reset_index()\n",
    "    # The -1 bin is the pair of one neuron with itself. Exclude.\n",
    "    df_cc = df_cc.loc[df_cc[\"xz\"] >= 0]\n",
    "    # columns: offset bin. index: neuron. values: observed \"P\", or NaN if the neuron has no other neuron at that offset\n",
    "    df_cc = df_cc.pivot(columns=[\"xz\", \"y\"], index=\"node_id\", values=\"P\")\n",
    "    # How to deal with NaN values? The default behavior of pandas is to ignore them, i.e. calculate correlation only\n",
    "    # for observations where neither of a pair is NaN. \n",
    "    # A more conservative approach is to assume that the neuron would have the overall mean connection probability.\n",
    "    # Finally we can add a small, random noise to all observations. That way, bins with all zeros will show up\n",
    "    # to have zero correlation with all others. Else they will have NaN correlation\n",
    "    if mode == \"valid\":\n",
    "        return df_cc.corr()\n",
    "    else:\n",
    "        return (df_cc.fillna(mn_P) + 1E-9 * numpy.random.rand(*df_cc.shape)).corr()\n",
    "    \n",
    "CC_pre = observations_to_cc_of_offset_bins(df_n_p_pre)\n",
    "CC_post = observations_to_cc_of_offset_bins(df_n_p_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a557e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers_y = numpy.hstack([\n",
    "    0.5 * (dbins_y[:-1] + dbins_y[1:]),\n",
    "    dbins_y[-1] + 0.5 * numpy.mean(numpy.diff(dbins_y))\n",
    "])\n",
    "bin_centers_xz = numpy.hstack([\n",
    "    0.5 * (dbins_xz[1:-1] + dbins_xz[2:]),\n",
    "    dbins_xz[-1] + 0.5 * numpy.mean(numpy.diff(dbins_xz[1:]))\n",
    "])\n",
    "\n",
    "CC_post = CC_post.drop(-1, axis=0, level=1).drop(-1, axis=1, level=1)\n",
    "CC_pre = CC_pre.drop(-1, axis=0, level=1).drop(-1, axis=1, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e707a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_index(idx):\n",
    "    idx = idx.to_frame().reset_index(drop=True)\n",
    "    idx[\"xz\"] = bin_centers_xz[idx[\"xz\"]]\n",
    "    idx[\"y\"] = bin_centers_y[idx[\"y\"]]\n",
    "    return pandas.MultiIndex.from_frame(idx)\n",
    "\n",
    "CC_post.index = translate_index(CC_post.index)\n",
    "CC_post.columns = translate_index(CC_post.columns)\n",
    "CC_pre.index = translate_index(CC_pre.index)\n",
    "CC_pre.columns = translate_index(CC_pre.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5986c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fn = \"/gpfs/bbp.cscs.ch/project/proj159/home/reimann/connectivity_higher_order_interactions.h5\"\n",
    "\n",
    "CC_pre.to_hdf(out_fn, key=\"{0}/{1}/pre\".format(loaded, thresh))\n",
    "CC_post.to_hdf(out_fn, key=\"{0}/{1}/post\".format(loaded, thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2950ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_edge_count_pre = df_n_p_pre.drop(-1, axis=0, level=0, errors=\"ignore\").drop(-1, axis=0, level=1, errors=\"ignore\").groupby([\"xz\", \"y\"]).apply(lambda _x: _x[\"N\"].mean())\n",
    "mn_edge_count_pre.index = translate_index(mn_edge_count_pre.index)\n",
    "mn_edge_count_post = df_n_p_post.drop(-1, axis=0, level=0, errors=\"ignore\").drop(-1, axis=0, level=1, errors=\"ignore\").groupby([\"xz\", \"y\"]).apply(lambda _x: _x[\"N\"].mean())\n",
    "mn_edge_count_post.index = translate_index(mn_edge_count_post.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdaddaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fn = \"/gpfs/bbp.cscs.ch/project/proj159/home/reimann/connectivity_higher_order_interactions.h5\"\n",
    "\n",
    "mn_edge_count_pre.to_hdf(out_fn, key=\"{0}/{1}/pre_N\".format(loaded, thresh))\n",
    "mn_edge_count_post.to_hdf(out_fn, key=\"{0}/{1}/post_N\".format(loaded, thresh))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluepysnap",
   "language": "python",
   "name": "bluepysnap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
